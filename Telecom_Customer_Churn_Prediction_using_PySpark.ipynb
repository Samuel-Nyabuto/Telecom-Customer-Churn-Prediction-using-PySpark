{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZkrnhgW1G1b",
        "outputId": "80c4165b-6654-4ad5-b14e-cd6fb3e746a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.4.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Installing PySpark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "from pyspark.ml.classification import LogisticRegression, GBTClassifier, LinearSVC\n",
        "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "metadata": {
        "id": "wWvyFCkM1mWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Creating a SparkSession\n",
        "spark = SparkSession.builder.appName(\"TelecomChurnPrediction\").getOrCreate()"
      ],
      "metadata": {
        "id": "SbfGsZW21t09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Loading  the dataset\n",
        "data = spark.read.csv(\"/content/telecom_dataset (1).csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Data Preprocessing\n",
        "data = data.dropna()  # Drop rows with missing values\n"
      ],
      "metadata": {
        "id": "cW7ZiUEU2IIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWgS4HS12d9V",
        "outputId": "0cd3a4c4-4f67-4632-d85e-97274845f77d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+---+--------------+--------------+------------+-----+\n",
            "|CustomerID|Gender|Age|      Contract|MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+---+--------------+--------------+------------+-----+\n",
            "|         1|Female| 25|Month-to-Month|          65.7|       156.5|   No|\n",
            "|         2|  Male| 37|      One Year|          89.0|      2356.8|   No|\n",
            "|         3|  Male| 52|      Two Year|         115.5|      5408.6|   No|\n",
            "|         4|Female| 30|Month-to-Month|          75.9|       129.4|  Yes|\n",
            "|         5|  Male| 45|      One Year|          98.2|      3142.0|   No|\n",
            "|         6|Female| 55|      Two Year|          99.9|      6541.5|   No|\n",
            "|         7|  Male| 32|Month-to-Month|          82.1|       267.7|  Yes|\n",
            "|         8|Female| 28|Month-to-Month|          61.5|       346.9|   No|\n",
            "|         9|  Male| 48|      One Year|         101.8|      5149.6|  Yes|\n",
            "|        10|Female| 60|      Two Year|         108.1|      6742.8|  Yes|\n",
            "|        11|  Male| 42|Month-to-Month|          78.9|       547.6|   No|\n",
            "|        12|Female| 35|      One Year|          94.7|      1950.2|   No|\n",
            "|        13|  Male| 41|      Two Year|          96.5|      4188.1|   No|\n",
            "|        14|  Male| 38|Month-to-Month|          79.1|       148.2|  Yes|\n",
            "|        15|Female| 50|      One Year|         105.5|      4759.1|  Yes|\n",
            "|        16|  Male| 47|      Two Year|         112.3|      5432.0|  Yes|\n",
            "|        17|Female| 26|Month-to-Month|          68.2|       289.1|   No|\n",
            "|        18|  Male| 33|Month-to-Month|          75.5|       462.5|  Yes|\n",
            "|        19|Female| 31|      One Year|          85.9|      1673.8|   No|\n",
            "|        20|  Male| 39|      Two Year|          97.1|      3992.4|   No|\n",
            "+----------+------+---+--------------+--------------+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Calculating call duration (assuming call_start_time and call_end_time columns are present)\n",
        "data = data.withColumn(\"call_duration\", (col(\"TotalCharges\") - col(\"MonthlyCharges\")) / 60)\n",
        "\n",
        "# Calculating average monthly spend\n",
        "data = data.withColumn(\"average_monthly_spend\", col(\"MonthlyCharges\"))\n",
        "\n",
        "# Display the updated dataset with new features\n",
        "data.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZS_6iMo6zE0",
        "outputId": "974d1341-e4ee-436e-cfaa-77eded88afa2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+---+--------------+--------------+------------+-----+------------------+---------------------+\n",
            "|CustomerID|Gender|Age|      Contract|MonthlyCharges|TotalCharges|Churn|     call_duration|average_monthly_spend|\n",
            "+----------+------+---+--------------+--------------+------------+-----+------------------+---------------------+\n",
            "|         1|Female| 25|Month-to-Month|          65.7|       156.5|   No|1.5133333333333332|                 65.7|\n",
            "|         2|  Male| 37|      One Year|          89.0|      2356.8|   No| 37.79666666666667|                 89.0|\n",
            "|         3|  Male| 52|      Two Year|         115.5|      5408.6|   No| 88.21833333333333|                115.5|\n",
            "|         4|Female| 30|Month-to-Month|          75.9|       129.4|  Yes|0.8916666666666667|                 75.9|\n",
            "|         5|  Male| 45|      One Year|          98.2|      3142.0|   No|50.730000000000004|                 98.2|\n",
            "|         6|Female| 55|      Two Year|          99.9|      6541.5|   No|            107.36|                 99.9|\n",
            "|         7|  Male| 32|Month-to-Month|          82.1|       267.7|  Yes|3.0933333333333333|                 82.1|\n",
            "|         8|Female| 28|Month-to-Month|          61.5|       346.9|   No| 4.756666666666666|                 61.5|\n",
            "|         9|  Male| 48|      One Year|         101.8|      5149.6|  Yes| 84.13000000000001|                101.8|\n",
            "|        10|Female| 60|      Two Year|         108.1|      6742.8|  Yes|110.57833333333333|                108.1|\n",
            "|        11|  Male| 42|Month-to-Month|          78.9|       547.6|   No| 7.811666666666667|                 78.9|\n",
            "|        12|Female| 35|      One Year|          94.7|      1950.2|   No|            30.925|                 94.7|\n",
            "|        13|  Male| 41|      Two Year|          96.5|      4188.1|   No| 68.19333333333334|                 96.5|\n",
            "|        14|  Male| 38|Month-to-Month|          79.1|       148.2|  Yes|1.1516666666666666|                 79.1|\n",
            "|        15|Female| 50|      One Year|         105.5|      4759.1|  Yes|             77.56|                105.5|\n",
            "|        16|  Male| 47|      Two Year|         112.3|      5432.0|  Yes| 88.66166666666666|                112.3|\n",
            "|        17|Female| 26|Month-to-Month|          68.2|       289.1|   No| 3.681666666666667|                 68.2|\n",
            "|        18|  Male| 33|Month-to-Month|          75.5|       462.5|  Yes|              6.45|                 75.5|\n",
            "|        19|Female| 31|      One Year|          85.9|      1673.8|   No|26.464999999999996|                 85.9|\n",
            "|        20|  Male| 39|      Two Year|          97.1|      3992.4|   No| 64.92166666666667|                 97.1|\n",
            "+----------+------+---+--------------+--------------+------------+-----+------------------+---------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKBJx6si9enN",
        "outputId": "96bed40c-d2ea-46c2-b236-e566b9dcc3be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Age: integer (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: double (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            " |-- call_duration: double (nullable = true)\n",
            " |-- average_monthly_spend: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encodinging categorical variables\n",
        "categorical_cols = ['Gender', 'Contract','Churn']\n",
        "indexers = [StringIndexer(inputCol=col, outputCol=col+'_index').fit(data) for col in categorical_cols]\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "dataset = pipeline.fit(data).transform(data)"
      ],
      "metadata": {
        "id": "rYOUXTw79WGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature scaling\n",
        "assembler = VectorAssembler(inputCols=['Age', 'average_monthly_spend', 'call_duration', 'Gender_index'], outputCol='features')\n",
        "dataset = assembler.transform(dataset)\n",
        "\n",
        "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')\n",
        "scaler_model = scaler.fit(dataset)\n",
        "dataset = scaler_model.transform(dataset)"
      ],
      "metadata": {
        "id": "NRvMTQpj-CBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data into training and testing sets\n",
        "(train_data, test_data) = dataset.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "WZCIajDxAEaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training and evaluation\n",
        "lr = LogisticRegression(labelCol='Churn_index', featuresCol='scaled_features')\n",
        "\n",
        "# Model selection and training\n",
        "classifiers = [\n",
        "    LogisticRegression(labelCol='Churn_index', featuresCol='scaled_features'),\n",
        "    RandomForestClassifier(labelCol='Churn_index', featuresCol='scaled_features'),\n",
        "    GBTClassifier(labelCol='Churn_index', featuresCol='scaled_features'),\n",
        "    LinearSVC(labelCol='Churn_index', featuresCol='scaled_features')\n",
        "]\n",
        "\n",
        "# Defining the parameter grid for each classifier\n",
        "paramGrids = [\n",
        "    ParamGridBuilder()\n",
        "        .addGrid(LogisticRegression.regParam, [0.1, 0.01])\n",
        "        .addGrid(LogisticRegression.elasticNetParam, [0.0, 0.5, 1.0])\n",
        "        .build(),\n",
        "    ParamGridBuilder()\n",
        "        .addGrid(RandomForestClassifier.numTrees, [10, 20, 30])\n",
        "        .addGrid(RandomForestClassifier.featureSubsetStrategy, ['auto', 'sqrt'])\n",
        "        .build(),\n",
        "    ParamGridBuilder()\n",
        "        .addGrid(GBTClassifier.maxDepth, [5, 10])\n",
        "        .addGrid(GBTClassifier.maxIter, [20, 30])\n",
        "        .build(),\n",
        "    ParamGridBuilder()\n",
        "        .addGrid(LinearSVC.maxIter, [10, 20])\n",
        "        .addGrid(LinearSVC.regParam, [0.1, 0.01])\n",
        "        .build()\n",
        "]\n",
        "\n",
        "\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='Churn_index')\n",
        "\n",
        "best_model = None\n",
        "best_accuracy = 0.0\n",
        "\n",
        "# Iterating over classifiers and parameter grids\n",
        "for classifier, paramGrid in zip(classifiers, paramGrids):\n",
        "    pipeline = Pipeline(stages=[classifier])\n",
        "    crossval = CrossValidator(estimator=pipeline,\n",
        "                              estimatorParamMaps=paramGrid,\n",
        "                              evaluator=evaluator,\n",
        "                              numFolds=5)\n",
        "    cv_model = crossval.fit(train_data)\n",
        "\n",
        "    # Model evaluation on test data\n",
        "    predictions = cv_model.transform(test_data)\n",
        "    accuracy = evaluator.evaluate(predictions)\n",
        "\n",
        "    print(f\"Accuracy for {classifier.__class__.__name__}: {accuracy}\")\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_model = cv_model.bestModel\n",
        "        best_accuracy = accuracy\n",
        "\n",
        "# Getting the best model and its parameters\n",
        "print(\"Best Model:\")\n",
        "print(best_model.stages[0])\n",
        "\n",
        "# Use the best model for predictions\n",
        "best_predictions = best_model.transform(test_data)\n",
        "\n",
        "# Performing evaluation on the best model\n",
        "best_accuracy = evaluator.evaluate(best_predictions)\n",
        "print(\"Best Model Accuracy:\", best_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3W2IEW8ANOk",
        "outputId": "8ef3f40c-51e1-40b6-d48b-f8fd865efd1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for LogisticRegression: 0.5\n",
            "Accuracy for RandomForestClassifier: 0.5\n",
            "Accuracy for GBTClassifier: 0.3333333333333333\n",
            "Accuracy for LinearSVC: 0.16666666666666666\n",
            "Best Model:\n",
            "LogisticRegressionModel: uid=LogisticRegression_91993ed58702, numClasses=2, numFeatures=4\n",
            "Best Model Accuracy: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol='Churn_index', predictionCol='prediction')\n",
        "\n",
        "# Evaluating the best model on test data\n",
        "accuracy = evaluator.evaluate(best_predictions, {evaluator.metricName: 'accuracy'})\n",
        "precision = evaluator.evaluate(best_predictions, {evaluator.metricName: 'weightedPrecision'})\n",
        "recall = evaluator.evaluate(best_predictions, {evaluator.metricName: 'weightedRecall'})\n",
        "f1_score = evaluator.evaluate(best_predictions, {evaluator.metricName: 'f1'})\n",
        "\n",
        "# Printing the evaluation results\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZWMmLQrHDb8",
        "outputId": "640a30b9-a508-4234-e18a-256e48de01f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Accuracy: 0.2\n",
            "Precision: 0.1\n",
            "Recall: 0.2\n",
            "F1-Score: 0.13333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Documentation: Telecom Customer Churn Prediction**\n",
        "1. **Introduction**\n",
        "The objective of this project is to predict customer churn in a telecom company using machine learning techniques implemented in PySpark. By accurately identifying customers at risk of churning, the company can take proactive measures to retain them and improve overall business performance.\n",
        "\n",
        "2. **Dataset**\n",
        "The telecom customer dataset used in this project was loaded from the file \"telecom_dataset.csv\". It contains information about customer demographics, usage patterns, service plans, call details, customer complaints, and churn status.\n",
        "\n",
        "3. **Preprocessing**\n",
        "The dataset underwent several preprocessing steps:\n",
        "\n",
        "**Missing Value Handling**: Rows with missing values were dropped using the dropna() method to ensure data integrity.\n",
        "Feature Engineering: Additional features were created to capture relevant information. The call duration was calculated as the difference between the total charges and monthly charges divided by 60. The average monthly spend feature was created by copying the monthly charges.\n",
        "4. **Feature Encoding and Scaling**\n",
        "Categorical variables, including \"Gender\", \"Contract\", and \"Churn\", were encoded using StringIndexer to convert them into numerical values. Feature scaling was applied using the StandardScaler to ensure that all features are on a similar scale.\n",
        "\n",
        "5. **Data Splitting**\n",
        "The data was split into training and testing sets with a ratio of 80:20 using the randomSplit() method.\n",
        "\n",
        "6. **Model Selection and Training**\n",
        "Four machine learning models were considered for churn prediction: Logistic Regression, Random Forest Classifier, Gradient Boosting Tree Classifier, and Linear Support Vector Classifier. For each model, a parameter grid was defined to tune the hyperparameters. Cross-validation with 5 folds was performed to evaluate the models and select the best model based on accuracy.\n",
        "\n",
        "7. **Model Evaluation**\n",
        "The selected model's performance was evaluated using a BinaryClassificationEvaluator. The best model was used to make predictions on the test data, and its accuracy was evaluated using a MulticlassClassificationEvaluator. The evaluation metrics calculated were accuracy, precision, recall, and F1-score.\n",
        "\n",
        "8. **Project Findings**\n",
        "Logistic Regression achieved the highest accuracy of 0.5, outperforming the other algorithms.\n",
        "The evaluation metrics (precision, recall, and F1-score) were low for the selected model, indicating room for improvement.\n",
        "The accuracy of the best model was 0.2, which is significantly lower than the accuracy achieved during training.\n",
        "The dataset and preprocessing steps might need further investigation to understand the reasons for low model performance.\n",
        "9. **Challenges Faced**\n",
        "Dealing with missing values required careful consideration of the best strategy, and in this case, dropping rows with missing values was chosen.\n",
        "Selecting the most suitable machine learning algorithm and tuning hyperparameters were challenging due to the lack of insights into the dataset and the specific problem domain.\n",
        "The low accuracy of the best model on the test data suggests potential issues with the data or feature engineering process.\n",
        "10. **Lessons Learned**\n",
        "Proper handling of missing values is crucial for accurate predictions, and alternative strategies like imputation can be explored.\n",
        "Feature engineering plays a significant role in improving model performance, but it requires a deep understanding of the domain and relevant features.\n",
        "Regular evaluation and comparison of different models using appropriate metrics help in selecting the best-performing model.\n",
        "Understanding the underlying reasons for low model performance is essential for model improvement and future iterations of the project.\n",
        "In conclusion, this project aimed to predict telecom customer churn using PySpark. Although the selected model did not perform well in terms of accuracy and evaluation metrics, the project provides valuable insights into the challenges and considerations involved in building churn prediction models. Further exploration and improvements can be made by refining the preprocessing steps, exploring additional features, and trying different machine learning algorithms and hyperparameter configurations."
      ],
      "metadata": {
        "id": "NQ_A-Gq6KUIz"
      }
    }
  ]
}